{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch indic-transliteration\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swmRBFgzfNb6",
        "outputId": "4860614b-1a15-473f-99ee-1a0af305cdc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Collecting indic-transliteration\n",
            "  Downloading indic_transliteration-2.3.52-py3-none-any.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.5)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (17.0.1)\n",
            "Collecting backports.functools-lru-cache (from indic-transliteration)\n",
            "  Downloading backports.functools_lru_cache-1.6.6-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.10.2)\n",
            "Collecting roman (from indic-transliteration)\n",
            "  Downloading roman-4.1-py3-none-any.whl (5.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (8.1.7)\n",
            "Installing collected packages: roman, backports.functools-lru-cache, indic-transliteration\n",
            "Successfully installed backports.functools-lru-cache-1.6.6 indic-transliteration-2.3.52 roman-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from indic_transliteration import sanscript\n",
        "\n",
        "# Load the model for English to Hindi translation\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "JT-oyRDoh885"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Input English sentence\n",
        "english_sentence = \" Definitely share your feedback in the comment section.\"\n",
        "\n",
        "# Tokenize and convert to tensor\n",
        "input_ids = tokenizer.encode(english_sentence, return_tensors=\"pt\")\n",
        "\n",
        "# Generate translation to Hindi\n",
        "translated = model.generate(input_ids)\n",
        "\n",
        "# Decode and print the translated sentence in Hindi\n",
        "hindi_translation = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "# Transliterate Hindi to Hinglish\n",
        "def transliterate_to_hinglish(hindi_text):\n",
        "    return sanscript.transliterate(hindi_text, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
        "\n",
        "hinglish_translation = transliterate_to_hinglish(hindi_translation)\n",
        "print(\"Hinglish Translation:\", hinglish_translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35Xpd6S5fWhp",
        "outputId": "717d0041-3695-4632-9232-4e6ea84e0cbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hinglish Translation: TippaNI khaNDa meM apanI pratikriyA ko nish{}chita hI sAjhA kareM |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentence = \" So even if it's a big video, I will clearly mention all the products.\"\n",
        "input_ids = tokenizer.encode(english_sentence, return_tensors=\"pt\")\n",
        "translated = model.generate(input_ids)\n",
        "hindi_translation = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "def transliterate_to_hinglish(hindi_text):\n",
        "    return sanscript.transliterate(hindi_text, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
        "\n",
        "hinglish_translation = transliterate_to_hinglish(hindi_translation)\n",
        "print(\"Hinglish Translation:\", hinglish_translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMzsGubqhJyK",
        "outputId": "9b713e01-3fa4-411a-b5ab-215ff00be071"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hinglish Translation: to yaha eka ba.DA vIDiyo hai, to bhI maiM spaShTa rUpa se sabhI utpAdoM kA ullekha kareMge|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentence = \" I was waiting for my bag\"\n",
        "input_ids = tokenizer.encode(english_sentence, return_tensors=\"pt\")\n",
        "translated = model.generate(input_ids)\n",
        "hindi_translation = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "def transliterate_to_hinglish(hindi_text):\n",
        "    return sanscript.transliterate(hindi_text, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
        "\n",
        "hinglish_translation = transliterate_to_hinglish(hindi_translation)\n",
        "print(\"Hinglish Translation:\", hinglish_translation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5qCw6gOhq5l",
        "outputId": "2f53d03b-dfeb-4e48-e779-281cdea4c684"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hinglish Translation: maiM apane baiga ke lie iMtajAra kara rahA thA\n"
          ]
        }
      ]
    }
  ]
}